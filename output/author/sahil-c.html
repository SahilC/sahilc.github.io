<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>Sahil C - Sahil C</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Sahil C</a></h1>
                <nav><ul>
                    <li><a href="/category/life.html">Life</a></li>
                    <li><a href="/category/paper.html">Paper</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/giraffe-representing-scenes-as-compositional-generative-neural-feature-fields.html">GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields</a></h1>
<footer class="post-info">
        <abbr class="published" title="2010-12-03T10:20:00+01:00">
                Published: Fri 03 December 2010
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/sahil-c.html">Sahil C</a>
        </address>
<p>In <a href="/category/paper.html">Paper</a>.</p>
<p>tags: <a href="/tag/paper.html">Paper</a> <a href="/tag/summary.html">Summary</a> <a href="/tag/research.html">Research</a> </p>
</footer><!-- /.post-info --><p>Authors:- Niemyer/Geiger et al. </p>
<p>Summary of the following <a href="https://arxiv.org/pdf/2011.12100.pdf">Paper</a>:-</p>
<ul>
<li>
<p>Hypothesis:- Incorporating a compositional 3D scene representation into generative models leads to controllable image generation.</p>
</li>
<li>
<p>Model allows for disentangled individual objects and allows for translating and rotating them in the scene, as well as changing camera pose. </p>
</li>
<li>
<p>Model claimed to generalize beyond training data, i.e. Can sythesize images not in training data -- more objects etc etc. </p>
</li>
<li>
<p>Combining an explicit 3D representation with neural rendering pipeline results in faster inference and more realistic images. </p>
</li>
<li>
<p>Most 3D neural renderers need camera pose as supervision, but this technique learns it from unstructured image collections. </p>
</li>
</ul>
<p><b>Pros</b></p>
<ul>
<li>
<p>Can render scenes in a compositional manner.</p>
</li>
<li>
<p>The scenes are realistic. </p>
</li>
<li>
<p>Does not use implicit supervision, and instead learns from unstructured sets of images. </p>
</li>
<li>
<p>Use 3D models of scenes rather than 2D images to learn. </p>
</li>
</ul>
<p><b>Cons</b></p>
<ul>
<li>
<p>Biases which are implicit in the datasets, do not get untangled during learning factors of variation. </p>
</li>
<li>
<p>For every parameter of variation, explicit control mechanisms need to provided at training time to learn them, i.e. Factors of variation are not learned explicitly. </p>
</li>
<li>
<p>The factors of variation probably influence the number of parameters -- despite the authors working in lower dimensional pixel space. </p>
</li>
</ul>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="/kevin-advice-to-build-a-great-life.html" rel="bookmark"
                           title="Permalink to Kevin' Advice to build a great life">Kevin' Advice to build a great life</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2010-12-03T10:20:00+01:00">
                Published: Fri 03 December 2010
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/sahil-c.html">Sahil C</a>
        </address>
<p>In <a href="/category/life.html">Life</a>.</p>
<p>tags: <a href="/tag/life.html">Life</a> <a href="/tag/summary.html">Summary</a> <a href="/tag/twitter.html">Twitter</a> </p>
</footer><!-- /.post-info -->                <p>Summary of the following <a href="https://twitter.com/Camp4/status/1402689150353129472">Twitter thread</a>:-</p>
<ul>
<li>The only thing that matter are relationships and experiences. </li>
<li>More Money == More problems -- You are time rich.</li>
<li>Edit your life to be minimalistic. </li>
<li>Be <a href="https://twitter.com/Camp4/status/1370798715057942534">multi-dimensional</a>.</li>
<li>Get fit -- Make it a lifestyle.</li>
<li>Write regularly. </li>
<li>Don't do dumb things.</li>
<li>Keep you burn rate low, even as â€¦</li></ul>
                <a class="readmore" href="/kevin-advice-to-build-a-great-life.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/n-beats-neural-basis-expansion-analysis-for-interpretable-time-series-forecasting.html" rel="bookmark"
                           title="Permalink to N-Beats: NEURAL BASIS EXPANSION ANALYSIS FOR INTERPRETABLE TIME SERIES FORECASTING">N-Beats: NEURAL BASIS EXPANSION ANALYSIS FOR INTERPRETABLE TIME SERIES FORECASTING</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2010-12-03T10:20:00+01:00">
                Published: Fri 03 December 2010
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/sahil-c.html">Sahil C</a>
        </address>
<p>In <a href="/category/paper.html">Paper</a>.</p>
<p>tags: <a href="/tag/paper.html">Paper</a> <a href="/tag/summary.html">Summary</a> <a href="/tag/research.html">Research</a> </p>
</footer><!-- /.post-info -->                <p>Summary of the following <a href="https://arxiv.org/pdf/1905.10437v4.pdf">Paper</a>:-</p>
<ul>
<li>
<p>Propose a new architecture for univariate time series forcasting. </p>
</li>
<li>
<p>Claim that the method is interpretable, and fast to train. </p>
</li>
<li>
<p>Add backward  + forward residual links and a very deep stack of layers.</p>
</li>
</ul>
<p>Pros</p>
<p>Cons</p>
<p>Questions</p>
                <a class="readmore" href="/n-beats-neural-basis-expansion-analysis-for-interpretable-time-series-forecasting.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>